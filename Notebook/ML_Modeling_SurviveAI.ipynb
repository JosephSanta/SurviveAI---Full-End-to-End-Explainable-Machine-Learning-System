{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94a37c4",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling — SurviveAI: Predicting Human Survival\n",
    "Ya tenemos los datos explorados y limpios. Ahora vamos a resumir los hallazgos clave y proponer próximos pasos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d0ddc3",
   "metadata": {},
   "source": [
    "## Cargar datos y separar X y y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4bbbbd",
   "metadata": {},
   "source": [
    "Aqui le decimos a la maquina que mirar (X) y que predecir (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2022976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('../Data/train_clean.csv')\n",
    "\n",
    "target = 'survived'\n",
    "\n",
    "y= df[target].astype('int')\n",
    "X= df.drop(columns=[target])    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135d573",
   "metadata": {},
   "source": [
    "### Explicacion facil de entender\n",
    "\n",
    "- X: Estas son las características o atributos que usaremos para hacer predicciones. En este caso, incluyen información sobre los pasajeros del Titanic, como su edad, sexo, clase de pasajero, tarifa pagada, etc. Estas características nos ayudan a entender el contexto y las condiciones de cada pasajero.\n",
    "- y: Esta es la variable objetivo que queremos predecir. En este caso, es si un pasajero sobrevivió o no al desastre del Titanic. Es una variable binaria donde 1 significa que el pasajero sobrevivió y 0 significa que no sobrevivió. Nuestro objetivo es entrenar un modelo de machine learning para predecir esta variable basándonos en las características (X) de los pasajeros.\n",
    "\n",
    "Eliminamos la columna target de X porque es la variable que queremos predecir, y no debe ser parte de las características que usamos para hacer la predicción. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be55ba2f",
   "metadata": {},
   "source": [
    "## DIVIDIR EN TRAIN Y TEST\n",
    "El modelo debe aprender de datos que no ha visto antes. Por eso dividimos los datos en dos partes: una para entrenar el modelo (train) y otra para probar su rendimiento (test). Usamos el 80% de los datos para entrenar y el 20% para probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae40707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42 , stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57308c78",
   "metadata": {},
   "source": [
    "### Explicacion facil de entender\n",
    "\n",
    "Basicamente, al dividir los datos en conjuntos de entrenamiento y prueba, nos aseguramos de que el modelo pueda generalizar bien a datos nuevos y no solo memorizar los datos con los que fue entrenado. Esto es crucial para evaluar su rendimiento de manera precisa.\n",
    "\n",
    "train el gimnasio donde el modelo aprende, y test es como un examen para ver que tanto aprendio.\n",
    "\n",
    "test_size=0.2 significa que el 20% de los datos se usaran para probar el modelo, y el 80% restante para entrenarlo.\n",
    "\n",
    "stratify=y asegura que la proporción de sobrevivientes y no sobrevivientes sea la misma en ambos conjuntos, lo que ayuda a mantener el equilibrio de clases durante el entrenamiento y la prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40819d12",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3a953",
   "metadata": {},
   "source": [
    "### Explicacion facil de entender\n",
    "El feature engineering es el proceso de transformar y crear nuevas características a partir de los datos originales para mejorar el rendimiento de un modelo de machine learning. En este caso, hemos realizado varias transformaciones en las características de los pasajeros del Titanic para hacerlas más útiles para el modelo. Estas transformaciones incluyen:\n",
    "- Crear una nueva característica que representa el tamaño de la familia del pasajero.\n",
    "- Indicar si el pasajero viajaba solo o acompañado.\n",
    "- Calcular la tarifa promedio por persona en la cabina.\n",
    "- Extraer el título del nombre del pasajero (por ejemplo, \"Mr\", \"Mrs\", \"Miss\") para capturar información sobre su estatus social.\n",
    "Estas nuevas características pueden proporcionar información adicional que ayuda al modelo a aprender patrones más complejos y mejorar su capacidad para predecir si un pasajero sobrevivió o no al desastre del Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05dc77e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re \n",
    "\n",
    "def add_features(df):\n",
    "    \n",
    "    # Creamos nuevas características basadas en las existentes\n",
    "    \n",
    "    # COPIAR EL DATAFRAME PARA EVITAR MODIFICAR EL ORIGINAL\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    \n",
    "    # Tamano de la familia\n",
    "    \n",
    "    df_clean[\"family_size\"] = df_clean[\"sibsp\"] + df_clean[\"parch\"] + 1 # +1 para incluir al propio pasajero\n",
    "    \n",
    "    # Viaja solo o acompañado\n",
    "\n",
    "    df_clean[\"is_alone\"] =  (df_clean[\"family_size\"] == 1).astype(int) #ponemos astype int para convertir True/False a 1/0\n",
    "\n",
    "    \n",
    "    # Tarifa por persona\n",
    "\n",
    "    df_clean [\"fare_per_person\"] = df_clean[\"fare\"] / df_clean[\"family_size\"] # dividimos la tarifa entre el tamano de la familia\n",
    "    \n",
    "    \n",
    "    # Extraer el titulo del nombre\n",
    "    \n",
    "    df_clean['title'] = df_clean['name'].str.extract(r',\\s*([^\\.]+)\\.', expand=False)\n",
    "    df_clean['title'] = df_clean['title'].replace(['Mlle','Ms'],'Miss').replace('Mme','Mrs')\n",
    "    return df_clean\n",
    "\n",
    "X_train = add_features(X_train)\n",
    "X_test = add_features(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 1) Quitar identificadores crudos (no informativos, causan overfitting)\n",
    "leak_cols = [\"name\", \"ticket\", \"passengerid\"]\n",
    "for c in leak_cols:\n",
    "    if c in X_train.columns:\n",
    "        X_train = X_train.drop(columns=c)\n",
    "    if c in X_test.columns:\n",
    "        X_test = X_test.drop(columns=c)\n",
    "\n",
    "# 2) Renombrar columnas para consistencia\n",
    "if \"Has_Cabin\" in X_train.columns and \"has_cabin\" not in X_train.columns:\n",
    "    X_train = X_train.rename(columns={\"Has_Cabin\": \"has_cabin\"})\n",
    "    X_test  = X_test.rename(columns={\"Has_Cabin\": \"has_cabin\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88726c98",
   "metadata": {},
   "source": [
    "## SEPARAR COLUMNAS NUMERICAS Y CATEGORICAS\n",
    "Para facilitar el procesamiento de los datos, separamos las columnas en dos grupos: numéricas y categóricas. Las columnas numéricas contienen valores cuantitativos (como edad, tarifa, etc.), mientras que las columnas categóricas contienen valores cualitativos (como sexo, clase de pasajero, etc.). Esta separación nos permite aplicar diferentes técnicas de preprocesamiento a cada tipo de dato.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "390d0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [c for c in X_train.columns if X_train[c].dtype.kind in \"if\"]\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa61cb",
   "metadata": {},
   "source": [
    "La primera linea crea una lista de nombres de columnas que contienen datos numéricos (tipos de datos enteros y flotantes). La segunda línea crea una lista de nombres de columnas que no están en la lista de columnas numéricas, es decir, las columnas categóricas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4a42a",
   "metadata": {},
   "source": [
    "## PIPELINE\n",
    "Un pipeline es una secuencia de pasos que se aplican a los datos para prepararlos y entrenar un modelo de machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936027ac",
   "metadata": {},
   "source": [
    "Es importante porque nos permite organizar y automatizar el proceso de preprocesamiento y modelado de datos. Al usar un pipeline, podemos asegurarnos de que los mismos pasos se apliquen de manera consistente tanto durante el entrenamiento del modelo como durante la predicción en nuevos datos. Esto ayuda a evitar errores y facilita la reproducibilidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8954a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09406d16",
   "metadata": {},
   "source": [
    "### Pipeline para columnas numericas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780966f1",
   "metadata": {},
   "source": [
    "Aqui definimos un pipeline para las columnas numéricas que incluye dos pasos:\n",
    "1. Imputación: Rellena los valores faltantes con la mediana de la columna.\n",
    "2. Escalado: Escala todos los numeros para que esten en un rango similar, lo que ayuda a mejorar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "340519da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tf =Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2ab48",
   "metadata": {},
   "source": [
    "### Pipeline para columnas categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad3af101",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6234a32",
   "metadata": {},
   "source": [
    "Basically, este pipeline para las columnas categóricas también tiene dos pasos:\n",
    "1. Imputación: Rellena los valores faltantes con la categoría más frecuente en cada columna.\n",
    "2. One-Hot Encoding: Convierte las categorías en una representación binaria (0s y 1s) para que el modelo pueda entenderlas mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49246e",
   "metadata": {},
   "source": [
    "### Combinar todo en un ColumnTransformer\n",
    "Finalmente, combinamos ambos pipelines (numérico y categórico) en un ColumnTransformer. Esto nos permite aplicar automáticamente el preprocesamiento adecuado a cada tipo de columna cuando entrenamos el modelo o hacemos predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "919697fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer([\n",
    "    ('num', num_tf, num_cols),\n",
    "    ('cat', cat_tf, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22fbfc",
   "metadata": {},
   "source": [
    "## PROBAR MODELOS\n",
    "Aqui probamos varios modelos de machine learning para ver cual funciona mejor con nuestros datos. Usamos validación cruzada para evaluar el rendimiento de cada modelo de manera más robusta.\n",
    "\n",
    "Primero , uno simple para tener una base , luego modelos mas complejos. Esto es para ver si los modelos mas complejos realmente aportan una mejora significativa en el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "853dd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "log_reg = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('clf', LogisticRegression(random_state=500))\n",
    "])\n",
    "\n",
    "rf = Pipeline([(\"prep\", preprocess),\n",
    "               (\"clf\", RandomForestClassifier(n_estimators=300, random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e7f65",
   "metadata": {},
   "source": [
    "## VALIDACION CRUZADA\n",
    "La validación cruzada es una técnica utilizada para evaluar el rendimiento de un modelo de machine learning de manera más robusta. En lugar de dividir los datos en un solo conjunto de entrenamiento y prueba, la validación cruzada divide los datos en varios subconjuntos (o \"folds\"). El modelo se entrena y evalúa múltiples veces, utilizando diferentes combinaciones de estos subconjuntos. Esto ayuda a asegurar que el modelo generalice bien a datos nuevos y no esté sobreajustado a un conjunto específico de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dc77667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy promedio: 0.827\n",
      "Random Forest Accuracy promedio: 0.816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for name, model in {\"Logistic\": log_reg, \"Random Forest\": rf}.items():\n",
    "    \n",
    "    scc = cross_val_score(model, X_train, y_train, cv=skf, scoring='accuracy').mean()\n",
    "\n",
    "    print(f\"{name} Accuracy promedio: {scc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a444e25",
   "metadata": {},
   "source": [
    "### Resultados de la validacion cruzada\n",
    "\n",
    "#### Regresion Logistica\n",
    "Logistic Accuracy promedio: 0.829\n",
    "\n",
    "Esto significa que el modelo de regresión logística tiene una precisión promedio del 82.9% en la predicción de si un pasajero sobrevivió o no al desastre del Titanic. En otras palabras, el modelo es capaz de clasificar correctamente el estado de supervivencia del 82.9% de los pasajeros en los datos de prueba durante la validación cruzada.\n",
    "\n",
    "#### Random Forest\n",
    "Random Forest Accuracy promedio: 0.817\n",
    "\n",
    "Esto significa que el modelo de Random Forest tiene una precisión promedio del 81.7% en la predicción de si un pasajero sobrevivió o no al desastre del Titanic. En otras palabras, el modelo es capaz de clasificar correctamente el estado de supervivencia del 81.7% de los pasajeros en los datos de prueba durante la validación cruzada.\n",
    "\n",
    "#### Comparacion\n",
    "En este caso, el modelo de regresión logística tiene una precisión ligeramente superior (82.9%) en comparación con el modelo de Random Forest (81.7%). Esto sugiere que, al menos en este conjunto de datos y con la configuración actual, la regresión logística es un poco más efectiva para predecir la supervivencia de los pasajeros del Titanic que el modelo de Random Forest\n",
    "\n",
    "Las relaciones entre variables como sexo , clase y edad son bastante lineales y directas, lo que favorece a la regresión logística.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3af3ce",
   "metadata": {},
   "source": [
    "## EVALUACION FINAL EN TEST \n",
    "Ahora si evaluamos el mejor modelo (Regresion Logistica) en el conjunto de test que no habia visto antes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705d493",
   "metadata": {},
   "source": [
    "### Eleccion del modelo\n",
    "Elegimos la regresion logistica porque tuvo mejor rendimiento en la validacion cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ac6d28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test: 0.8379888268156425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       110\n",
      "           1       0.80      0.77      0.79        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.83      0.82      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(\"Accuracy en test:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803d9b6",
   "metadata": {},
   "source": [
    "### Interpretacion de resultados\n",
    "Vemos que el logistic regression tuvo un accuracy de 0.84 en el conjunto de test, lo que indica que el modelo es capaz de clasificar correctamente el estado de supervivencia del 84% de los pasajeros en los datos de prueba.\n",
    "\n",
    "#### Precision, Recall y F1-Score CLASE 0 \n",
    "- Precision (Precisión): De todos los que el modelo dijo que murio el 87 % realmente murio. Esto significa que el modelo es bastante confiable cuando predice que un pasajero no sobrevivió.\n",
    "- Recall (Sensibilidad): De todos los que realmente murieron, el modelo identifico correctamente , un 88 % de ellos. Esto indica que el modelo es efectivo para detectar a los pasajeros que no sobrevivieron.\n",
    "- F1-Score: El F1-Score es una medida que combina la precisión y el recall en un solo valor. Un F1-Score alto (0.88 para la clase negativa) indica que el modelo tiene un buen equilibrio entre precisión y recall.\n",
    "- Soporte: El soporte indica la cantidad de muestras reales en cada clase. En este caso, hay 110 pasajeros que no sobrevivieron y 58 que sí sobrevivieron en el conjunto de prueba.\n",
    "\n",
    "#### Precision, Recall y F1-Score CLASE 1\n",
    "- Precision (Precisión): De todos los que el modelo dijo que sobrevivio el 81 % realmente sobrevivio. Esto significa que el modelo es bastante confiable cuando predice que un pasajero sobrevivió.\n",
    "- Recall (Sensibilidad): De todos los que realmente sobrevivieron, el modelo identifico correctamente , un 80 % de ellos. Esto indica que el modelo es efectivo para detectar a los pasajeros que sobrevivieron.\n",
    "- F1-Score: El F1-Score es una medida que combina la precisión y el recall en un solo valor. Un F1-Score alto (0.80 para la clase positiva) indica que el modelo tiene un buen equilibrio entre precisión y recall.\n",
    "- Soporte: El soporte indica la cantidad de muestras reales en cada clase. En este caso, hay 69 pasajeros que sobrevivieron.\n",
    "\n",
    "#### Promedio generales \n",
    "- Accuray: Acierta en 85 de cada 100 predicciones.\n",
    "- Macro avg: Promedio simple de precision, recall y f1-score sin considerar el soporte. Un 84 es bastante bueno.\n",
    "- Weighted avg: Promedio ponderado de precision, recall y f1-score considerando el soporte de cada clase. Un 85 es bastante bueno. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c1440",
   "metadata": {},
   "source": [
    "## SABER QUE VIO EL MODELO PARA DECIDIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9004712a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>title_Master</td>\n",
       "      <td>1.342951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sex_female</td>\n",
       "      <td>0.828403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>title_Mrs</td>\n",
       "      <td>0.685654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>has_cabin</td>\n",
       "      <td>0.387301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>title_Major</td>\n",
       "      <td>0.313811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>embarked_Q</td>\n",
       "      <td>0.291117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>title_Sir</td>\n",
       "      <td>0.259750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fare</td>\n",
       "      <td>0.146176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>title_Lady</td>\n",
       "      <td>0.079688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>title_Col</td>\n",
       "      <td>0.076728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Coefficient\n",
       "22  title_Master     1.342951\n",
       "11    sex_female     0.828403\n",
       "25     title_Mrs     0.685654\n",
       "5      has_cabin     0.387301\n",
       "21   title_Major     0.313811\n",
       "14    embarked_Q     0.291117\n",
       "27     title_Sir     0.259750\n",
       "4           fare     0.146176\n",
       "20    title_Lady     0.079688\n",
       "16     title_Col     0.076728"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener nombres finales\n",
    "ohe = log_reg.named_steps[\"prep\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "cat_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "final_names = num_cols + cat_names\n",
    "\n",
    "# Obtener coeficientes del modelo logístico\n",
    "coefs = log_reg.named_steps[\"clf\"].coef_[0]\n",
    "\n",
    "# Crear DataFrame ordenado\n",
    "pd.DataFrame({\"Feature\": final_names, \"Coefficient\": coefs}) \\\n",
    "  .sort_values(\"Coefficient\", ascending=False) \\\n",
    "  .head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1024e88b",
   "metadata": {},
   "source": [
    " ### Importancia de las caracteristicas\n",
    "\n",
    "El modelo de Regresión Logística muestra las variables que más influyen en la probabilidad de supervivencia. A continuación se interpretan los coeficientes positivos (que aumentan las probabilidades de sobrevivir) y los más relevantes del modelo final:\n",
    "\n",
    "- title_Master (+1.34) → Los pasajeros con el título Master (niños varones) tenían alta probabilidad de sobrevivir, debido a la regla histórica “women and children first”.\n",
    "- sex_female (+0.82) → Ser mujer incrementa fuertemente la probabilidad de supervivencia. Fue el factor más dominante en la mayoría de los casos.\n",
    "- title_Mrs (+0.68) → Mujeres casadas (mayores o acompañadas) también mostraron alta tasa de supervivencia, en parte por estatus y prioridad en evacuación.\n",
    "- has_cabin (+0.38) → Tener cabina indica mejores condiciones de alojamiento y proximidad a las cubiertas de rescate.\n",
    "- title_Major (+0.31) → Aunque minoritario, este título refleja un estatus social alto, lo que podía facilitar el acceso a botes.\n",
    "- embarked_Q (+0.29) → Pasajeros que embarcaron en Queenstown (Q) mostraron una leve mayor probabilidad, probablemente por diferencias en la composición social del grupo.\n",
    "- title_Sir, title_Lady, title_Col → Títulos de nobleza o militares que reflejan posición privilegiada o acompañamiento, asociados con mejores resultados.\n",
    "- fare (+0.14) → Un precio de boleto mayor tiende a correlacionarse con clases superiores, por lo tanto con mayor supervivencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15327d82",
   "metadata": {},
   "source": [
    "## GUARDAR MODELO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a24b7be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en: /Users/joseph/Documents/ia-projects/Kaggle/SurviveAI---Full-End-to-End-Explainable-Machine-Learning-System/models/surviveai_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "model_path = Path(\"../models/surviveai_model.joblib\")\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(log_reg, model_path)\n",
    "print(f\"✅ Modelo guardado en: {model_path.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
